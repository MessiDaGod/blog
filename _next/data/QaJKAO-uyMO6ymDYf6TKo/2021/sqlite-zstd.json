{"pageProps":{"post":{"filename":"2021/sqlite-zstd.md","frontmatter":{"csl":"../ieee-with-url.csl","date":"2021-01-24","hidden":true,"references":[],"subtitle":"","title":"sqlite-zstd: Transparent row-level compression for SQLite","url2cite-link-output":"sup"},"preview":"For my incomplete time-tracking tool, I store snapshots of the windows I have open in order to later analyze what I spend my time on. This data is pretty redundant - the open program doesn’t change that much, but I still want a snapshot every 30 seconds. Story? There’s a few solutions I could think ","content_ast":[{"t":"Para","c":[{"t":"Str","c":"For my "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"incomplete time-tracking tool"}],["https://github.com/phiresky/timetrackrs",""]]},{"t":"Str","c":", I store snapshots of the windows I have open in order to later analyze what I spend my time on. This data is pretty redundant - the open program doesn’t change that much, but I still want a snapshot every 30 seconds. "},{"t":"Strikeout","c":[{"t":"Str","c":"Story"}]},{"t":"Str","c":"?"}]},{"t":"Para","c":[{"t":"Str","c":"There’s a few solutions I could think of when you have compressible data in your database:"}]},{"t":"BulletList","c":[[{"t":"Para","c":[{"t":"Str","c":"Just store the data compressed individually. On insert, compress(data), on every select decompress it."}]},{"t":"Para","c":[{"t":"Str","c":"This is easy to implement and easy to use. But it’s also not that effective, especially if your column contains JSON data since JSON stores the keys together with the data, separately in every row."}]}],[{"t":"Para","c":[{"t":"Str","c":"Split the database into separate files (for example weekly), then compress the older partitions into single files."}]},{"t":"Para","c":[{"t":"Str","c":"If you need to access older data, simply decompress the whole week of data to RAM, then read from that database. This would work okay for my use case since it’s pretty much append-only time-series data; older data is not read often, and when it is it is read pretty sequentially."}]},{"t":"Para","c":[{"t":"Str","c":"This idea is kind of similar to table partitioning and tablespaces in PostgreSQL. In SQLite you can attach multiple database files into a single instance using "},{"t":"Code","c":[["",[],[]],"ATTACH DATABASE"]},{"t":"Str","c":", and then join across tables of the different files."}]}]]},{"t":"Para","c":[{"t":"Str","c":"create table compressible(id integer primary key not null, data text); insert into compressible(data) select case abs(random() % 2) when true then "},{"t":"Quoted","c":[{"t":"SingleQuote"},[{"t":"Str","c":"{"},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"foobar"}]]},{"t":"Str","c":": "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"hello world"}]]},{"t":"Str","c":"}"}]]},{"t":"Str","c":" when false then "},{"t":"Quoted","c":[{"t":"SingleQuote"},[{"t":"Str","c":"{"},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"yello"}]]},{"t":"Str","c":": "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"nopify"}]]},{"t":"Str","c":"}"}]]},{"t":"Str","c":" end from generate_series(1, 1000000);"}]}],"default":{"filename":"2021/sqlite-zstd.md","frontmatter":{"csl":"../ieee-with-url.csl","date":"2021-01-24","hidden":true,"references":[],"subtitle":"","title":"sqlite-zstd: Transparent row-level compression for SQLite","url2cite-link-output":"sup"},"preview":"For my incomplete time-tracking tool, I store snapshots of the windows I have open in order to later analyze what I spend my time on. This data is pretty redundant - the open program doesn’t change that much, but I still want a snapshot every 30 seconds. Story? There’s a few solutions I could think ","content_ast":[{"t":"Para","c":[{"t":"Str","c":"For my "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"incomplete time-tracking tool"}],["https://github.com/phiresky/timetrackrs",""]]},{"t":"Str","c":", I store snapshots of the windows I have open in order to later analyze what I spend my time on. This data is pretty redundant - the open program doesn’t change that much, but I still want a snapshot every 30 seconds. "},{"t":"Strikeout","c":[{"t":"Str","c":"Story"}]},{"t":"Str","c":"?"}]},{"t":"Para","c":[{"t":"Str","c":"There’s a few solutions I could think of when you have compressible data in your database:"}]},{"t":"BulletList","c":[[{"t":"Para","c":[{"t":"Str","c":"Just store the data compressed individually. On insert, compress(data), on every select decompress it."}]},{"t":"Para","c":[{"t":"Str","c":"This is easy to implement and easy to use. But it’s also not that effective, especially if your column contains JSON data since JSON stores the keys together with the data, separately in every row."}]}],[{"t":"Para","c":[{"t":"Str","c":"Split the database into separate files (for example weekly), then compress the older partitions into single files."}]},{"t":"Para","c":[{"t":"Str","c":"If you need to access older data, simply decompress the whole week of data to RAM, then read from that database. This would work okay for my use case since it’s pretty much append-only time-series data; older data is not read often, and when it is it is read pretty sequentially."}]},{"t":"Para","c":[{"t":"Str","c":"This idea is kind of similar to table partitioning and tablespaces in PostgreSQL. In SQLite you can attach multiple database files into a single instance using "},{"t":"Code","c":[["",[],[]],"ATTACH DATABASE"]},{"t":"Str","c":", and then join across tables of the different files."}]}]]},{"t":"Para","c":[{"t":"Str","c":"create table compressible(id integer primary key not null, data text); insert into compressible(data) select case abs(random() % 2) when true then "},{"t":"Quoted","c":[{"t":"SingleQuote"},[{"t":"Str","c":"{"},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"foobar"}]]},{"t":"Str","c":": "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"hello world"}]]},{"t":"Str","c":"}"}]]},{"t":"Str","c":" when false then "},{"t":"Quoted","c":[{"t":"SingleQuote"},[{"t":"Str","c":"{"},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"yello"}]]},{"t":"Str","c":": "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"nopify"}]]},{"t":"Str","c":"}"}]]},{"t":"Str","c":" end from generate_series(1, 1000000);"}]}]}}},"__N_SSG":true}